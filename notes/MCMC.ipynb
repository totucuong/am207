{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\newcommand{\\Ex}{\\mathbb{E}}\n",
    "\\newcommand{\\Var}{\\mathrm{Var}}\n",
    "\\newcommand{\\Cov}{\\mathrm{Cov}}\n",
    "\\newcommand{\\SampleAvg}{\\frac{1}{N({S})} \\sum_{s \\in {S}}}\n",
    "\\newcommand{\\indic}{\\mathbb{1}}\n",
    "\\newcommand{\\avg}{\\overline}\n",
    "\\newcommand{\\est}{\\hat}\n",
    "\\newcommand{\\trueval}[1]{#1^{*}}\n",
    "\\newcommand{\\Gam}[1]{\\mathrm{Gamma}#1}\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\renewcommand{\\like}{\\cal L}\n",
    "\\renewcommand{\\loglike}{\\ell}\n",
    "\\renewcommand{\\err}{\\cal E}\n",
    "\\renewcommand{\\dat}{\\cal D}\n",
    "\\renewcommand{\\hyp}{\\cal H}\n",
    "\\renewcommand{\\Ex}[2]{E_{#1}[#2]}\n",
    "\\renewcommand{\\x}{\\mathbf x}\n",
    "\\renewcommand{\\v}[1]{\\mathbf #1}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook, we will illustrate how to sample from a Markov chain and introduce two MCMC algorithms: Metropolis-Hastings and Gibbs sampling."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Markov chain sampling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Metropolis-Hastings\n",
    "\n",
    "The Metropolis-Hasting algorithm is a general recipe that lets us start with any irreducible Markov chain on the state space of interest and then modify it into a new Markov chain that has desired stationary distribution\n",
    "\n",
    "Our goal is to modify a MC P to construct a MC $X_0, X_1, \\dots$ with stationary distribution $s$. The pseudocode is as follows.\n",
    "\n",
    "1. Start at any state $X_0$ (choosen randomly or deterministically)\n",
    "2. If $X_n = i$, propose a new state j using the transition probabilities in the ith row of the original transition matrix P.\n",
    "3. Compute the acceptance probability $a_{ij} = min(\\frac{s_jp_{ij}}{s_ip_{ij}},1)$\n",
    "4. Flip a coin that lands Heads with probability $a_{ij}$\n",
    "5. If the coin lands Heads, accept the proposal (i.e., go to j) setting $X_{n+1} = j$. Otherwise, reject the proposal (i.e., stay at i), setting $X_{n+1} = i$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Some examples with code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gibbs sampling\n",
    "\n",
    "Gibss sampling is an MCMC algorithm for obtaining approximate draws from a joint distribution, based on sampling from **conditional** distributions one at a time: at each stage, one variable is updated (keeping all other varibles fixed) by drawing from the condtional distributions of that variable given all other variables.\n",
    "\n",
    "This approach is very useful when we have conditional distributions that are pleasant to work with.\n",
    "\n",
    "We have to major Gibbs samplers:\n",
    "\n",
    "1. Systematic scan Gibbs sampler: components (dimensions, variables) are updated one by one in order\n",
    "2. Random scan Gibbs sampler: a randomly chosen component is update at each stag.\n",
    "\n",
    "We illustrate Gibbs sampler in the context of bivariate $p(X,Y)$ and both $X, Y$ are discrete.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Systematic scan Gibbs sampler**: Let X and Y be discrete r.v.s with joint PMF $p_{X,Y}(x,y) = p(X=x, Y=y)$. We wish to construct a two-dimensional Markov chain $(X_n, Y_n)$ whose stationary distribution is $p_{X,Y}$. If the current state is $(X_n, Y_n) = (x_n,y_n)$, then:\n",
    "\n",
    "1. Draw a value $x_{n+1}$ from the conditional distribution of X given $Y = y_n$ and set $X_{n+1} = x_{n+1}$\n",
    "2. Draw a value $y_{n+1}$ from the conditional distribution of Y given $X = x_{n+1}$, and set $Y_{n+1} = y_{n+1}$\n",
    "3. Repeat step 1 and step 2 over and over, the stationary distribution of the chain $(X_0, Y_0),(X_1, Y_1), \\dots$ is $p_{X,Y}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Random scan Gibbs sampler** The difference compared to systematic scan Gibbs sampler is that in each stage, it picks a unifomrly random component and updates it, according to the conditional distributions given the other component:\n",
    "\n",
    "1. Choose which component to update, with equal probabilities.\n",
    "2. If the X-coponent was chosen, draw a value $x_{n+1}$ from the conditional distribution of X given $Y = y_n$ and set $X_{n+1}= x_{n+1}, Y_{n+1} = y_n$. We do similar update if $Y_n$ is choosen to update.\n",
    "3. Repeat steps 1 and 2 over and over, the stationary distribution of the chain $(X_0, Y_0), (X_1, Y_1), \\dots$ is $p_{X,Y}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
