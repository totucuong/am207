{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/totucuong/miniconda3/envs/experiment/bin/python\n"
     ]
    }
   ],
   "source": [
    "!which python\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python 3.6.0\n"
     ]
    }
   ],
   "source": [
    "!python --version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import os\n",
    "from collections import defaultdict\n",
    "from sklearn.cluster import MiniBatchKMeans\n",
    "import numpy as np\n",
    "import scipy.stats\n",
    "import torch\n",
    "from torch.distributions import constraints\n",
    "from matplotlib import pyplot\n",
    "%matplotlib inline\n",
    "\n",
    "import pyro\n",
    "import pyro.distributions as dist\n",
    "from pyro.optim import Adam\n",
    "from pyro.infer import SVI, TraceEnum_ELBO, config_enumerate\n",
    "\n",
    "smoke_test = ('CI' in os.environ)\n",
    "pyro.enable_validation(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "K=4\n",
    "true_weight = torch.tensor([0.06, 0.4, 0.4, 0.04])\n",
    "true_mu = torch.tensor([2., 20., 45., 60.])\n",
    "true_scale= torch.tensor([10., 5., 1., 20.])\n",
    "N= 100000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "assignment = dist.Categorical(true_weight).expand_by([N])()\n",
    "data = dist.Normal(true_mu[assignment], true_scale[assignment])()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "pyplot.hist(data, bins=100, alpha=0.4, color='r');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "K = 4\n",
    "def init_locs(data, K):\n",
    "    cluster = MiniBatchKMeans(batch_size=100, n_clusters=K)\n",
    "    cluster.fit(data.view(len(data), -1))\n",
    "    return torch.tensor(cluster.cluster_centers_.squeeze()).type(torch.float32)\n",
    "\n",
    "mus = init_locs(data, K)\n",
    "\n",
    "def model(data):\n",
    "    # Global parameters.\n",
    "    weights = pyro.param('weights', torch.ones(K) / K, constraint=constraints.simplex)\n",
    "    locs = pyro.param('locs', mus)\n",
    "    scales = pyro.param('scales', 0.5 * torch.ones(K), constraint=constraints.positive)\n",
    "\n",
    "    with pyro.iarange('data', len(data)) as ind:\n",
    "        # Local variables.\n",
    "        assignment = pyro.sample('assignment',\n",
    "                                 dist.Categorical(weights).expand_by([len(ind)]))\n",
    "        pyro.sample('obs', dist.Normal(locs[assignment], scales[assignment]), obs=data.index_select(0, ind))\n",
    "\n",
    "@config_enumerate(default='parallel')\n",
    "def guide(data):\n",
    "    with pyro.iarange('data', len(data), subsample_size=10000) as ind:\n",
    "        # Local parameters.\n",
    "#         print('sampled index', ind)\n",
    "        assignment_probs = pyro.param('assignment_probs', torch.ones(len(data), K) / K,\n",
    "                                      constraint=constraints.unit_interval)\n",
    "        pyro.sample('assignment', dist.Categorical(assignment_probs[ind]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "optim = pyro.optim.Adam({'lr': 0.02, 'betas': [0.9, 0.99]})\n",
    "inference = SVI(model, config_enumerate(guide, 'parallel'), optim,\n",
    "                loss=TraceEnum_ELBO(max_iarange_nesting=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pyro.set_rng_seed(1)      # Set seed to make results reproducible.\n",
    "pyro.clear_param_store()  # Clear stale param values.\n",
    "\n",
    "# Register hooks to monitor gradient norms.\n",
    "gradient_norms = defaultdict(list)\n",
    "inference.loss(model, guide, data)  # Initializes param store.\n",
    "for name, value in pyro.get_param_store().named_parameters():\n",
    "    value.register_hook(lambda g, name=name: gradient_norms[name].append(g.norm().item()))\n",
    "\n",
    "losses = []\n",
    "for i in range(5000 if not smoke_test else 2):\n",
    "    loss = inference.step(data)\n",
    "    losses.append(loss)\n",
    "    if (i % 100 == 0):\n",
    "        print('loss at {}th epoch is {}'.format(i, loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pyplot.figure(figsize=(10,3), dpi=100).set_facecolor('white')\n",
    "pyplot.plot(losses)\n",
    "pyplot.xlabel('iters, lr=0.001')\n",
    "pyplot.ylabel('loss')\n",
    "pyplot.yscale('log')\n",
    "pyplot.title('Convergence of SVI');\n",
    "pyplot.savefig('elbo_svi_lr_0001.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "losses[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(gradient_norms['locs'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pyplot.figure(figsize=(10,4), dpi=100).set_facecolor('white')\n",
    "for name, grad_norms in gradient_norms.items():\n",
    "    pyplot.plot(grad_norms[:1000], label=name)\n",
    "pyplot.xlabel('iters')\n",
    "pyplot.ylabel('gradient norm')\n",
    "pyplot.yscale('log')\n",
    "pyplot.legend(loc='best')\n",
    "pyplot.title('Gradient norms during SVI');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = pyro.param('weights')\n",
    "locs = pyro.param('locs')\n",
    "scales = pyro.param('scales')\n",
    "print('weights = {}'.format(weights.data.numpy()))\n",
    "print('locs = {}'.format(locs.data.numpy()))\n",
    "print('scales = {}'.format(scales.data.numpy()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assignment = dist.Categorical(weights).expand_by([N])()\n",
    "syn = dist.Normal(locs[assignment], scales[assignment])()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pyplot.hist(syn.detach().numpy(), bins=100, alpha=0.2, color='b', label='synthetic');\n",
    "pyplot.hist(data+10, bins=100, alpha=0.2, color='r', label='real right-shifted by 10');\n",
    "pyplot.legend();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "true_weight,true_mu , true_scale"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lesson learnt\n",
    "\n",
    "1. The weights of components should be well-balanced. Otherwise it is very hard to capture all the modes.\n",
    "2. The greater data variance is the large subsample size should be during training."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
